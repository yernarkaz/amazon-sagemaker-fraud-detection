{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b2dcd6-f674-4aca-aa6d-222361c73165",
   "metadata": {},
   "source": [
    "## Bonus Lab - Detect bias using SageMaker Clarify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf9009-7471-42c9-b1f5-477053b63639",
   "metadata": {},
   "source": [
    "Amazon SageMaker Clarify provides machine learning developers with greater visibility into their training data and models so they can identify and limit bias and explain predictions. Biases are imbalances in the training data or prediction behavior of the model across different groups, such as age or income bracket. Biases can result from the data or algorithm used to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e5e35-4830-4619-85aa-8004d10dc5fa",
   "metadata": {},
   "source": [
    "In the below section, we would want to run a pretraining bias job to examine our training dataset for bias.\n",
    "\n",
    "We would normally pick sensitive groups which might be prone to bias and run analysis. In our example, we pick customer gender to analyze how it is skewed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ced045-b6c3-42cf-96fb-d07039f7d8a7",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b6d3c-f31c-4722-b70a-263544455161",
   "metadata": {},
   "source": [
    "Start by installing the tools you'll need to detect and address bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84a60b-7d6f-409b-bfb9-ed12ecc85bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1\n",
    "# install the tools we're going to use to detect and deal with bias\n",
    "\n",
    "!pip install -U imbalanced-learn==0.7.0 awswrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe03d10-9eeb-4802-9d6c-fe1cbf941f5b",
   "metadata": {},
   "source": [
    "This is a continuation of Lab 1 after the training dataset was created. Since we're picking up the lab after the training dataset was uploaded we're going to use the same few variables that point to the dataset. The following variables are populated with the default values. If you didn't change the bucket name and training dataset name, you don't need to change anything in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821aea7-113e-4880-8170-441b15f5223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "# pull the prefix and bucket variables from storemagic. running the store -r command will give\n",
    "# you access to the bucket and prefix variables\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67553576-85e0-4d63-b0da-eaa547d8bee3",
   "metadata": {},
   "source": [
    "If you see any error that says unable to retrieve variable sagemaker_session, please ignore it. We're going to create a new sagemaker session in the next few cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcbdb02-8bc9-4379-bd7a-983287d70847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "\n",
    "print(f\"Bucket is {bucket}\")\n",
    "print(f\"Prefix is {prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86232923-ce8a-4e2e-b786-493ed536d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4\n",
    "\n",
    "train_data_uri = f\"s3://{bucket}/{prefix}/data/train/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cfa9f-7275-4731-9092-e0347e992c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# Reference that session\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# create a sagemaker client\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "# then link the two\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session, sagemaker_client=sagemaker_boto_client\n",
    ")\n",
    "\n",
    "# create an s3 client\n",
    "s3_client = boto3.client(\"s3\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2307d8-ee34-4cc0-bce6-54e1eb8e0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "# comment the line below if you want to use a separate role\n",
    "# sagemaker_execution_role_name = \"AmazonSageMaker-ExecutionRole-20210107T234882\"\n",
    "\n",
    "# Get the default role that was created for this domaim\n",
    "try:\n",
    "    sagemaker_role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    sagemaker_role = iam.get_role(RoleName=sagemaker_execution_role_name)[\"Role\"][\"Arn\"]\n",
    "    print(f\"\\n instantiating sagemaker_role with supplied role name : {sagemaker_role}\")\n",
    "\n",
    "# Get temporary access credentials\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75319c9-137a-4b73-a252-115527dad5b2",
   "metadata": {},
   "source": [
    "First - pull the training data set from our S3 bucket using DataWrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88308c2-46a7-4159-98f2-d189aadf3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "# features selected for training\n",
    "train_cols = wr.s3.read_csv(train_data_uri).columns.to_list()\n",
    "\n",
    "# our bias report will be saved at this path\n",
    "bias_report_1_output_path = f\"s3://{bucket}/{prefix}/clarify-output/bias_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53103a-a7a1-48c8-96b7-b57a9f2da661",
   "metadata": {},
   "source": [
    "Create the `SageMakerClarifyProcessor` instance to initiate a clarify job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6319ac5-924d-455a-a77f-6b41a7234293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f047c-dfea-483e-a408-a64c1a47adab",
   "metadata": {},
   "source": [
    "Next, configure the input dataset, where to store the output, the label column targeted with a `DataConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605fb8e-037b-47a7-80db-092c7c238770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_uri,\n",
    "    s3_output_path=bias_report_1_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35b1d8-3b90-41a3-986b-123a4ab9f2a0",
   "metadata": {},
   "source": [
    "Use `BiasConfig` to provide information on which columns contain the facets (sensitive groups, customer_gender_female), what the sensitive features (facet_values_or_threshold) might be, and what the desirable outcomes are (label_values_or_threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be834eb0-0dfd-403a-990b-4b034c1d5ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"customer_gender_female\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfeff59-c75e-4e2d-bdf9-8b98a704ccc5",
   "metadata": {},
   "source": [
    "Now run the clarify job if it hasn't been run already. When it is ran, store the job name and cache the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e253a52-97ba-48dd-8706-e0b0d4ac6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "\n",
    "if 'clarify_bias_job_1_name' not in locals():\n",
    "\n",
    "    clarify_processor.run_pre_training_bias(\n",
    "        data_config=bias_data_config,\n",
    "        data_bias_config=bias_config)\n",
    "\n",
    "    clarify_bias_job_1_name = clarify_processor.latest_job.name\n",
    "    %store clarify_bias_job_1_name\n",
    "\n",
    "else:\n",
    "    print(f'Clarify job {clarify_bias_job_1_name} has already run successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a356d-c9c5-4e25-b5bc-2a22f4aa802c",
   "metadata": {},
   "source": [
    "## Result analysis\n",
    "\n",
    "You can verify the class imbalance that Clarify reports on our training dataset. We have pre run the bias detection and use the output json below to print the class imbalance.  A classification data set with skewed class proportions is said to be imbalanced. Classes that make up a large proportion of the data set are called majority classes. Those that make up a smaller proportion are minority classes. This is problematic because the training model will spend most of its time on majority examples and not learn enough from minority ones. \n",
    "\n",
    "In this case `female` is a minority class and under represented in our dataset which might impact our model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da4c35-48fd-4e02-8a81-184c356f29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "\n",
    "if \"clarify_bias_job_1_name\" in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket=bucket,\n",
    "        Key=f\"{prefix}/clarify-output/bias_1/analysis.json\",\n",
    "        Filename=\"outputs/bias_1_analysis.json\",\n",
    "    )\n",
    "    print(f\"Downloaded analysis from previous Clarify job: {clarify_bias_job_1_name}\")\n",
    "else:\n",
    "    print(f\"Loading pre-generated analysis file...\")\n",
    "\n",
    "with open(\"./outputs/bias_1_analysis.json\", \"r\") as f:\n",
    "    bias_analysis = json.load(f)\n",
    "\n",
    "results = bias_analysis[\"pre_training_bias_metrics\"][\"facets\"][\"customer_gender_female\"][0][\n",
    "    \"metrics\"\n",
    "][1]\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6bf7c0-d553-4d50-aa91-faa01a6e7445",
   "metadata": {},
   "source": [
    "## Fix the imbalance/bias\n",
    "To fix class imbalance, we use a popular technique called SMOTE (Synthetic Minority Oversampling Technique) which basically oversamples the minority class meaining duplicating the minority class synthetically in your training dataset to balance the skew for customer gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f9668-256c-446b-8fc9-cc746363e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13\n",
    "\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "gender = train[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7fa14-f7d3-4f33-b14c-0549837c6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 14\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train, gender)\n",
    "train_data_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5732c2-5259-4e32-aaca-a082f6f041d4",
   "metadata": {},
   "source": [
    "Now you can see that we are able to effectively duplicate the female values. Now let's get the file loaded to s3 to run Clarify again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edabfcf-0011-44ce-af1e-63bfe8ad8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "\n",
    "train_data_upsampled.to_csv(\"./data/upsampled_train.csv\", index=False)\n",
    "train_data_upsampled_s3_path = f\"s3://{bucket}/{prefix}/data/train/upsampled/train.csv\"\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"./data/upsampled_train.csv\",\n",
    "    Bucket=bucket,\n",
    "    Key=f\"{prefix}/data/train/upsampled/train.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc51786-868d-44c4-b249-5e31e308184f",
   "metadata": {},
   "source": [
    "## Re-run and see the new bias results\n",
    "\n",
    "Let's re-run the previous few steps to get the new bias values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d2873-ee7f-4dd0-a0c8-8a6724c6e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "\n",
    "train_cols = wr.s3.read_csv(train_data_upsampled_s3_path).columns.to_list()\n",
    "bias_report_2_output_path = f\"s3://{bucket}/{prefix}/clarify-output/bias_2\"\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=train_data_upsampled_s3_path,\n",
    "    s3_output_path=bias_report_2_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_cols,\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"customer_gender_female\",\n",
    "    facet_values_or_threshold=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac72e3-7fea-4dcf-a4f2-997246e098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 17\n",
    "\n",
    "if 'clarify_bias_job_2_name' not in locals():\n",
    "\n",
    "    clarify_processor.run_pre_training_bias(\n",
    "        data_config=bias_data_config,\n",
    "        data_bias_config=bias_config)\n",
    "\n",
    "    clarify_bias_job_2_name = clarify_processor.latest_job.name\n",
    "    %store clarify_bias_job_2_name\n",
    "\n",
    "else:\n",
    "    print(f'Clarify job {clarify_bias_job_2_name} has already run successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa600568-d6e6-4ecb-92fd-e7bb01edb846",
   "metadata": {},
   "source": [
    "If you run the below cell, you can see that class imbalance is now reduced to zero. This shows that our SMOTE worked and the dataset is not biased for gender anymore.In the next section, we will kick off a training job to train a XGBoost model using this training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9018624-bda5-4043-9c77-4b3b5e2f778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 18\n",
    "\n",
    "if \"clarify_bias_job_2_name\" in locals():\n",
    "    s3_client.download_file(\n",
    "        Bucket=bucket,\n",
    "        Key=f\"{prefix}/clarify-output/bias_2/analysis.json\",\n",
    "        Filename=\"outputs/bias_2_analysis.json\",\n",
    "    )\n",
    "    print(f\"Downloaded analysis from previous Clarify job: {clarify_bias_job_2_name}\")\n",
    "else:\n",
    "    print(f\"Loading pre-generated analysis file...\")\n",
    "\n",
    "with open(\"./outputs/bias_2_analysis.json\", \"r\") as f:\n",
    "    bias_analysis = json.load(f)\n",
    "\n",
    "results = bias_analysis[\"pre_training_bias_metrics\"][\"facets\"][\"customer_gender_female\"][0][\n",
    "    \"metrics\"\n",
    "][1]\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc4587-75ba-4609-8193-f14dedf1be41",
   "metadata": {},
   "source": [
    "Congratulations! You have finished the bonus lab - Detect Bias using SageMaker Clarify"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
